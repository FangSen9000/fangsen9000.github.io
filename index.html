<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Sen Fang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">房森 (Sen Fang)</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="talk.html">Talks</a></div>
<div class="menu-item"><a href="schedule.html">Schedule</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="project.html">Projects</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
<div class="menu-item"><a href="award.html">Awards</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Sen Fang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="file/senfang_photo_2024-1.jpg" alt="photo_senfang" height="201px" />&nbsp;</td>
<td align="left"><p><br>
  <b>Sen Fang</b><br>
  Ph.D. Student<br>
  <a href="https://www.cs.rutgers.edu/">Department of Computer Science</a> <br>
  <a href="https://en.wikipedia.org/wiki/Rutgers_University">Rutgers, The State University of New Jersey</a><br>
  <a href="https://scholar.google.com/citations?hl=en&user=BJb9MsgAAAAJ">Google Scholar</a> | <a href="https://github.com/fangsen9000/">Github</a> | <a href="https://orcid.org/0009-0007-9463-4491">ORCID</a> | <a href="https://twitter.com/SenFang01">Twitter</a><br>
  <a href="https://openreview.net/profile?id=~Sen_Fang2">OpenReview</a> | <a href="https://www.linkedin.com/in/fangsen/">Linkedin</a> | <a href="https://github.com/FangSen9000/FangSen9000/issues/1">All-Emails</a><br>
  Email: fangsen2024 [at] gmail [dot] com<br><br></p>
</td></tr></table>
<p><br></p>
<p>
  I'm <strong><font color='red'>Sen Fang</font></strong>, a first-year Ph.D. student at 
  <a href="https://en.wikipedia.org/wiki/Rutgers_University">Rutgers University</a>, supervised by 
  <a href="https://people.cs.rutgers.edu/~dnm/">Prof. Dimitris Metaxas</a>.
</p>
<p>
  My main research field is <strong>Multimodal</strong>. My research interest covers <strong>Audio-Visual</strong> 
  (talking-face and representation of text/audio, Audio Generated Image), <strong>AIGC</strong> (AI-generated content, 
  Multi-view learning, NeRF/3D), <strong>Self-Supervised</strong> Learning (Pose recognition and modeling, object & action 
  detection/recognition in videos, Medical Image Analysis) and <strong>VR/AR/DCG</strong> and <strong>Visual Perception</strong> 
  (Enables the agent to make plan and navigate)!
</p>
<p>
  Recently I have been interested in the following topic:
  <ul>
      <li><strong><font color='green'>LLM/HCI/Embodied Intelligence</font></strong> - I will bring agents that can interact with 
      scenes or people to reality, whatever it takes.</li>
      <li><strong><font color='green'>Identify and Model Behavior</font></strong> - particularly in perceiving and synthesizing 
      dynamic humans, objects, and scenes. I think controlling robots by self-supervised training through real-world data and 
      Computer Vision related technologies is the right path.</li>
      <li><strong><font color='green'>Sign Language</font></strong> - It involves many fields, such as the conversion between text/audio 
        and movement/gestures, human body reconstruction and recognition, human pose synchronization, Pose-guided image generation, 
        avatar reconstruction,  and style transfer, etc. 
        This topic has high technical requirements, and you must achieve a high level in all the above fields 
        before it can be applied to sign language datasets.</li>
  </ul>
</p>
<p>
  I am open to academic collaborations, and please drop me an email if you are interested in collaborating with me. I am currently looking for a 25 Summer Intern, if your company has a position, please contact me.
</p>
<h2>Recent News</h2>
<ul>
<li><strong>2024.6</strong> I got the <a href="https://jwc.henu.edu.cn/info/2145/8713.htm">Best Bachelor's Thesis</a> award of <a href="https://en.wikipedia.org/wiki/Henan_University">Henan University</a>.</li>
<!--<li><strong>2024.5</strong> I made a brief contact, just hopefully work as an Intern in Microsoft in 25 Summer.</li>-->
<li><strong>2024.2</strong> I have received the offer of dream advisor and will start my doctoral career.</li> 
</ul>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <b><span>→</span>&nbsp;<a href="biography.html">Full list of News</a></b>

<h2>Selected Papers</h2>
* Equivalent contribution, † Corresponding author
<br>
<br>
<table class="imgtable"><tbody><tr><td>
  <img src="cover/SignLLM.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> SignLLM: Sign Language Production Large Language Models
  </b> <br>
  <u><b>Sen Fang</b></u>, Lei Wang, Ce Zheng, Chunyu Sui, Mingyu Zhao, Yapeng Tian, Chen Chen<sup>†</sup>
  <br>
  <i>arXiv:2405.10718</i> <br>
  [<a href="https://arxiv.org/abs/2405.10718">Paper</a>]  [<a href="https://signllm.github.io/">Project Website</a>]  [<a href="https://signllm.github.io/Prompt2Sign">Prompt2Sign Dataset</a>] 
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/BGTAI.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b>Bridging the Gap between Text, Audio, Image, and Any Sequence: A Novel Approach using Gloss-based Annotation
  </b> <br>
  <u><b>Sen Fang</b></u>, Sizhou Chen<sup>*</sup>, Yalin Feng, Xiaofeng Zhang, Teik Toe Teoh<sup>†</sup>
  <br>
  <i>Preprint'24</i> <br>
  [Paper]  [<a href="paper/ICASSP_24_BGTAI.pdf">Local-PDF</a>]
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
    <img src="cover/SignDiff.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
    <td align="left"><p><b> SignDiff: Diffusion Models for American Sign Language Production
    </b> <br>
    <u><b>Sen Fang</b></u>, Chunyu Sui<sup>*</sup>, Yanghao Zhou, Xuedong Zhang, Hongbin Zhong, Minyu Zhao, Yapeng Tian<sup>†</sup>, Chen Chen<sup>†</sup>
    <br>
    <i>arXiv:2308.16082</i> <br>
    [<a href="https://arxiv.org/abs/2308.16082">Paper</a>]  [<a href="https://signdiff.github.io">Project Page</a>]  [<a href="https://github.com/SignDiff/Processed-Data">Preprocessed Data</a>]    
    </p></td></tr></tbody></table>
<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <b><span>→</span>&nbsp;<a href="publication.html">Full list of Publication</a></b>

<h2>Part of Friends (random sort)</h2>
<details class="tip">
  <summary class="">Extend</summary>
  <br>
  <p>Georgia Institute of Technology: <a href="https://github.com/rjzhb">Hongbin Zhong</a></p>
  <p>Columbia University: <a href="https://github.com/capsfly">Chunyu Sui</a></p>
  <p>Toronto University: <a href="https://github.com/Wulf">Haris Khan</a></p>
  <p>Tsinghua University: <a href="https://www.jiayinzhu.xyz/home">Jiayin Zhu</a></p>
  <p>University of Waterloo: <a>Yifan Wang</a></p>
  <p>Nanyang Technological University: <a href="https://yalin-feng.github.io">Yalin Feng</a></p>
  <p>University of Washington: <a href="https://www.linkedin.com/in/yangyang-wu-2759181b3/">Yangyang Wu</a></p>
  </details>
  <br>

<div style="width: 420px; height: 220px; overflow: hidden;">
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=DVOirx5xZoatWTrQvYVH2Jzv9fHuoX_NoHOytFe_XOo&cl=ffffff&w=a"></script>
</div>
<div id="footer">
  <div id="footer-text">
    © Copyright 2022-2025 Sen Fang. Powered by <a href="https://github.com/jem/jemdoc" target="blank">jemdoc</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: August 30, 2024.
  </div>
</div>
  
</td>
</tr>
</table>
</body>
<!-- 
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=5gilyx79ipr&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0" async="async"></script>
-->
</html>

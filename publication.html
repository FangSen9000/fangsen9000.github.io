<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
  <div class="menu-category">房森 (Sen Fang)</div>
  <div class="menu-item"><a href="index.html">Home</a></div>
  <div class="menu-item"><a href="biography.html">Biography</a></div>
  <div class="menu-item"><a href="talk.html">Talks</a></div>
  <div class="menu-item"><a href="schedule.html">Schedule</a></div>
  <div class="menu-category">Research</div>
  <div class="menu-item"><a href="publication.html" class="current">Publications</a></div>
  <div class="menu-item"><a href="project.html">Projects</a></div>
  <div class="menu-item"><a href="service.html">Service</a></div>
  <div class="menu-item"><a href="award.html">Awards</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Selected Publications & Manuscripts</h1>
</div>

<h2>Summary</h2>

* Equivalent contribution, † Corresponding author
<br>
<br>
XXX. My Full list of Publication at <b>&nbsp;<a href="https://scholar.google.com/citations?hl=en&user=BJb9MsgAAAAJ">Google Scholar</a></b>
<!--
<h2>Working Paper</h2>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/SignLLM.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> Sign-X: Foundation for Sign Language Understand Models
  </b> <br>
  <u><b>Sen Fang</b></u>, Hongwei Ye, Hongbin Zhong, Minyu Zhao, Dimitris N. Metaxas<sup>†</sup>
  <br>
  <i>arXiv:2405.10718</i> <br>
  [<a href="https://arxiv.org/abs/2405.10718">Paper</a>]  [<a href="https://signllm.github.io/">Project Website</a>]  [<a href="https://signllm.github.io/Prompt2Sign">Prompt2Sign Dataset</a>] 
  </p></td></tr></tbody></table>
-->

<h2>Selected Preprints</h2>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/SignX.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> SignX: The Foundation Model for Sign Recognition
  </b> <br>
  <u><b>Sen Fang</b></u>, Chunyu Sui, Hongwei Yi, Carol Neidle, Dimitris N. Metaxas<sup>†</sup>
  <br>
  <i>Preprint'25</i> <br>
  [<a href="https://arxiv.org/abs/2504.16315">Paper</a>]  [<a href="paper/ICCV_25_SignX.pdf">Local-PDF</a>]
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/SignLLM.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> SignLLM: Sign Language Production Large Language Models
  </b> <br>
  <u><b>Sen Fang</b></u>, Lei Wang, Ce Zheng, Chunyu Sui, Yapeng Tian, Chen Chen<sup>†</sup>
  <br>
  <i>arXiv:2405.10718</i> <br>
  [<a href="https://arxiv.org/abs/2405.10718">Paper</a>]  [<a href="https://signllm.github.io/">Project Website</a>]  [<a href="https://signllm.github.io/Prompt2Sign">Prompt2Sign Dataset</a>] 
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/sizhou_asr.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks
  </b> <br>
  Sizhou Chen, Songyang Gao, <u><b>Sen Fang</b></u>
  <br>
  <i>arXiv:2309.07765</i> <br>
  [<a href="https://arxiv.org/abs/2309.07765">Paper</a>]
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/BGTAI.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b>Bridging the Gap between Text, Audio, Image, and Any Sequence: A Novel Approach using Gloss-based Annotation
  </b> <br>
  <u><b>Sen Fang</b></u>, Sizhou Chen<sup>*</sup>, Yalin Feng, Xiaofeng Zhang, Teik Toe Teoh<sup>†</sup>
  <br>
  <i>Preprint'24</i> <br>
  [<a href="">Paper</a>]  [<a href="paper/ICASSP_24_BGTAI.pdf">Local-PDF</a>]
  </p></td></tr></tbody></table>

<h2>Selected Publications</h2>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/SignDiff.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> SignDiff: Diffusion Model for American Sign Language Production
  </b> <br>
  <u><b>Sen Fang</b></u>, Chunyu Sui<sup>*</sup>, Yanghao Zhou, Xuedong Zhang, Hongbin Zhong, Yapeng Tian<sup>†</sup>, Chen Chen<sup>†</sup>
  <br>
  <i>IEEE FG FM&LLM&GM 2025</i> <br>
  [<a href="https://arxiv.org/abs/2308.16082">Paper</a>]  [<a href="https://signdiff.github.io">Project Page</a>]  [<a href="https://github.com/SignDiff/Processed-Data">Preprocessed Data</a>]  
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/UniBriVL.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> UniBriVL: Robust Universal Representation and Generation of Audio Driven Diffusion Models
  </b> <br>
  <u><b>Sen Fang</b></u>, Bowen Gao, Yangjian Wu, Teik Toe Teoh<sup>†</sup>
  <br>
  <i>EMNLP MRL 2023</i> <br>
  [<a href="https://aclanthology.org/2023.mrl-1.1/">Paper</a>]  [<a href="https://github.com/FangSen9000/BriVL-Generation/">Code</a>]
  </p></td></tr></tbody></table>

<table class="imgtable"><tbody><tr><td>
  <img src="cover/Wav2BriVL.png" alt="" width="180px" height="100px">&nbsp; &nbsp; &nbsp;</td>
  <td align="left"><p><b> Exploring Efficient-Tuned Learning Audio Representation Method from BriVL
  </b> <br>
  <u><b>Sen Fang</b></u>, Yangjian Wu, Bowen Gao, Jingwen Cai, Teik Toe Teoh<sup>†</sup>
  <br>
  <i>ICONIP 23</i> <br>
  [<a href="https://link.springer.com/chapter/10.1007/978-981-99-8184-7_4">Paper</a>]  [<a href="https://arxiv.org/abs/2303.04585">arXiv</a>]  [<a href="slides/WavBriVL_conceptual_part.pptx">PPT</a>]
  </p></td></tr></tbody></table>


</td>
</tr>
</table>
</body>
</html>
